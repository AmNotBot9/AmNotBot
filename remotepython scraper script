Python
import httpx
from parsel import Selector
import pandas as pd
import json

# Fetch the job listings page
response = httpx.get("https://www.remotepython.com/jobs/")
assert response.status_code == 200

# Parse HTML content
selector = Selector(text=response.text)
jobs = []

for job in selector.css('.box-list .item'):
    # Extract job details
    title = job.css('h3 a::text').get()
    relative_url = job.css('h3 a::attr(href)').get()
    full_url = response.url.join(relative_url)
    snippet = job.css('div p::text').get() or "No description available"

    # Determine experience level and job type based on keywords
    if "entry-level" in snippet.lower() or "less than 2 years" in snippet.lower():
        experience = "Entry-level"
    else:
        experience = "N/A"

    if "remote" in snippet.lower():
        job_type = "Remote"
    else:
        job_type = "On-site"

    # Create a job dictionary
    jobs.append({
        "Job Title": title,
        "URL": str(full_url),
        "Experience": experience,
        "Job Type": job_type,
        "Description": snippet
    })

# Export data to CSV, Excel, and JSON
save_path = r'C:\Users\81sig\Documents'

# Export to CSV
df = pd.DataFrame(jobs)
df.to_csv(f'{save_path}\\cybersecurity_jobs.csv', index=False)

# Export to Excel
df.to_excel(f'{save_path}\\cybersecurity_jobs.xlsx', index=False)

# Export to JSON
with open(f'{save_path}\\cybersecurity_jobs.json', 'w') as json_file:
    json.dump(jobs, json_file, indent=4)

print("Data exported to cybersecurity_jobs.csv, cybersecurity_jobs.xlsx, and cybersecurity_jobs.json in C")
Use code with caution.




Explanation of Functions:

Import Necessary Libraries:

httpx: Used for making HTTP requests to fetch the job listings page.
parsel: A CSS selector library for parsing HTML content.
pandas: A data manipulation and analysis library for creating DataFrames and exporting data to CSV and Excel.
json: For working with JSON data and exporting to JSON format.
Fetch Job Listings:

response = httpx.get("https://www.remotepython.com/jobs/"): Sends an HTTP GET request to the specified URL and stores the response in the response variable.
assert response.status_code == 200: Checks if the request was successful (status code 200) and raises an assertion error if not.
Parse HTML Content:

selector = Selector(text=response.text): Creates a Selector object from the HTML content of the response.
jobs = []: Initializes an empty list to store the extracted job information.
Iterate Over Job Listings:

for job in selector.css('.box-list .item'): Iterates over each job listing element in the HTML content.
Extract Job Details:

title = job.css('h3 a::text').get(): Extracts the job title using CSS selectors.
relative_url = job.css('h3 a::attr(href)').get(): Extracts the relative URL of the job listing.
full_url = response.url.join(relative_url): Constructs the full URL by joining the base URL with the relative URL.
snippet = job.css('div p::text').get() or "No description available": Extracts the job description snippet, or sets it to "No description available" if not found.
Determine Experience Level and Job Type:

Checks if the snippet contains keywords like "entry-level" or "less than 2 years" to determine the experience level.
Checks if the snippet contains the keyword "remote" to determine the job type.
Create Job Dictionary:

Creates a dictionary with the extracted job details, including the job title, URL, experience level, job type, and description.
Appends the dictionary to the jobs list.
Export Data to CSV, Excel, and JSON:

Sets the save path for the exported files.
Creates a pandas DataFrame from the jobs list.
Exports the DataFrame to CSV and Excel formats using the to_csv() and to_excel() methods.
Exports the jobs list to JSON format using the json.dump() method.
Print Message:

Prints a message indicating that the data has been successfully exported.






